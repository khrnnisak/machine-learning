{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_feature(data):\n",
    "    n_max = max(data)\n",
    "    n_min = min(data)\n",
    "    l_data = len(data)\n",
    "\n",
    "    for i in range(0, l_data):\n",
    "        data[i] = (data[i] - n_min) / (n_max - n_min)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.375, 0.125, 0.5, 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [10, 25, 15, 30, 50]\n",
    "\n",
    "n_data = norm_feature(data)\n",
    "n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.11111111],\n",
       "       [0.        , 1.        ],\n",
       "       [0.45652174, 0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[100, 0.01],\n",
    "        [8, 0.05],\n",
    "        [50, 0.005]\n",
    "        ]\n",
    "\n",
    "np_data = np.asarray(data)\n",
    "mm_scaler = MinMaxScaler()\n",
    "mm_data= mm_scaler.fit_transform(data)\n",
    "mm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats\n",
    "from statistics import mean, pstdev, stdev\n",
    "\n",
    "\n",
    "def std_feature(data):\n",
    "    baris_data = data.shape[0]\n",
    "    kolom_data =  data.shape[1]\n",
    "\n",
    "    for i in range(0, baris_data):\n",
    "        for j in range(0, kolom_data):\n",
    "            data[i][j] = (data[i][j] - mean(data[:, j])) / pstdev(data[:, j])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[100, 0.001],\n",
    "        [8, 0.05],\n",
    "        [50, 0.005],\n",
    "        [88, 0.07],\n",
    "        [4, 0.1]\n",
    "        ]\n",
    "data_1 = [100, 0.01]\n",
    "\n",
    "data = np.asarray(data)\n",
    "\n",
    "#std_data = std_feature(data)\n",
    "#std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26398112, -1.16389967],\n",
       "       [-1.06174414,  0.12639634],\n",
       "       [ 0.        , -1.05856939],\n",
       "       [ 0.96062565,  0.65304778],\n",
       "       [-1.16286263,  1.44302493]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss_scaler = StandardScaler()\n",
    "\n",
    "std_data = ss_scaler.fit_transform(data)\n",
    "std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "oe = [['POLINEMA'],\n",
    "        ['PENS'],\n",
    "        ['PNJ'],\n",
    "        ['PNP'],\n",
    "        ['POLBAN']\n",
    "]\n",
    "\n",
    "ord_oe = ordinal_encoder.fit_transform(oe)\n",
    "oh_oe = OneHotEncoder().fit_transform(oe)\n",
    "oh_oe.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "            'the house had a tiny little mouse',\n",
    "            'the cat saw the mouse',\n",
    "            'the mouse ran away from the house',\n",
    "            'the cat finally ate the mouse',\n",
    "            'the end of the mouse story'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4755751 , 0.58946308, 0.28088232, 0.        , 0.        ,\n",
       "         0.        , 0.58946308],\n",
       "        [0.        , 0.        , 0.58873218, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.34771471, 0.        , 0.72971837,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.58946308, 0.        , 0.        , 0.        ,\n",
       "         0.4755751 , 0.        , 0.28088232, 0.58946308, 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.58946308, 0.        , 0.4755751 , 0.        , 0.58946308,\n",
       "         0.        , 0.        , 0.28088232, 0.        , 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.67009179, 0.        ,\n",
       "         0.        , 0.        , 0.31930233, 0.        , 0.        ,\n",
       "         0.67009179, 0.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unittest import result\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "result = vect.fit_transform(corpus)\n",
    "#print(vect.get_feature_names())\n",
    "#print(result.toarray())\n",
    "result.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The house had a tiny little mouse',\n",
       " ' The cat saw the mouse ',\n",
       " 'The mouse ran away from the house']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = 'The house had a tiny little mouse. The cat saw the mouse .The mouse ran away from the house'\n",
    "\n",
    "stc_split = sentences.split('.')\n",
    "stc_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
